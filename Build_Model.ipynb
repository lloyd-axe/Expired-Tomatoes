{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276a43ef",
   "metadata": {},
   "source": [
    "# How to create classifier model using custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142843cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from ModellingUtils import ModellingUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534699a",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "We will use the **Imdb (aclImdb) dataset** for this implementation. You can obtain the training, testing, and validation data from the dataset using the **text_dataset_from_directory** method of the **ModellingUtils** module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7e0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\Lloyd Acha\\Documents\\ACHA_Files\\Projects\\Programming\\DataSets\\aclImdb_v1\\aclImdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e0d838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, class_names, val_ds = ModellingUtils.text_dataset_from_directory(\n",
    "    os.path.join(DATA_PATH, 'train')\n",
    "    )\n",
    "test_ds = ModellingUtils.text_dataset_from_directory(\n",
    "    os.path.join(DATA_PATH, 'test'), \n",
    "    subset = None, \n",
    "    validation_split = 0,\n",
    "    seed = 0,\n",
    "    validation = False\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b0b9e",
   "metadata": {},
   "source": [
    "We will also use pretrained models from **TensorFlow Hub**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "377dd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "model_url = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d056df",
   "metadata": {},
   "source": [
    "**ModellingUtils** module also **build_classifier_model** method that will automatically build a specific model from the pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea526e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'default': (None,   28763649    ['preprocessing[0][0]',          \n",
      "                                512),                             'preprocessing[0][1]',          \n",
      "                                 'pooled_output': (               'preprocessing[0][2]']          \n",
      "                                None, 512),                                                       \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 512)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            513         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,764,162\n",
      "Trainable params: 28,764,161\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ModellingUtils.build_classifier_model(preprocess_url, model_url)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d18f9",
   "metadata": {},
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8132b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model = ModellingUtils.train_model(model, \n",
    "                                       data = train_ds, \n",
    "                                       epochs = 5, \n",
    "                                       validation_data = val_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
